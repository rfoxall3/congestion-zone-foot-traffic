{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38097974-5144-4382-a852-e1681e07b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up API backend and useful packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from ast import literal_eval\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0eea6c-1f03-4ccc-bd41-527f3d9a1db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#installs'\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/Dewey-Data/deweydatapy.git #installs Dewey Data package for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c911f08-38a6-456b-a256-fbfed3870fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deweydatapy as ddp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c352cc-09d6-44c9-8848-bd591eaceb02",
   "metadata": {},
   "source": [
    "## API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d182c3-4d33-4435-b907-aa92920d6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#individual key (get your own!)\n",
    "API_KEY = '7LQsijkY.KX88klG0wxYG3kNa7P4sgWDHLJaf2czgQTtR3PDb39mfCoX9S9PHit3B'\n",
    "#dec 24 to feb 25\n",
    "url25 = f\"https://app.deweydata.io/external-api/v3/products/ff6af5ab-fe02-4ea3-9a24-5fad03700b38/files\"\n",
    "#jan 24\n",
    "url24 = f\"https://app.deweydata.io/external-api/v3/products/712cd497-9ff8-45a6-b15b-b14ea3ba5146/files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bdbd1c-6c24-4c05-b403-e1e0897107ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting files information for page 1/1...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 1\n",
      "Total number of files: 3\n",
      "Total files size (MB): 545.79\n",
      "Average single file size (MB): 181.93\n",
      "Date partition column: DATE_RANGE_START\n",
      "Expires at: 2025-02-27T19:29:51.349Z\n",
      "-----------------------------------------------------------------\n",
      "Start downloading...\n",
      " \n",
      "Downloading 1/3 (file index = 0)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Jan_24-0-DATE_RANGE_START-2024-01-01.csv\n",
      "Skipping...\n",
      "Downloading 2/3 (file index = 1)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Jan_24-1-DATE_RANGE_START-2024-01-01.csv\n",
      "Skipping...\n",
      "Downloading 3/3 (file index = 2)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Jan_24-2-DATE_RANGE_START-2024-01-01.csv\n",
      "Skipping...\n",
      " \n",
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "ddp.download_files0(API_KEY, url24, \"C:/Users/rf2694\",\n",
    "                    start_date = '2024-01-01', end_date = '2024-01-31', skip_exists=True) #be sure to change the directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8eab55-5ad6-4ca6-b3e2-9ccd62bfeea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting files information for page 1/1...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 1\n",
      "Total number of files: 3\n",
      "Total files size (MB): 437.46\n",
      "Average single file size (MB): 145.82\n",
      "Date partition column: DATE_RANGE_START\n",
      "Expires at: 2025-02-27T19:29:52.098Z\n",
      "-----------------------------------------------------------------\n",
      "Start downloading...\n",
      " \n",
      "Downloading 1/3 (file index = 0)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Dec_24_to_Feb_25-0-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 2/3 (file index = 1)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Dec_24_to_Feb_25-1-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 3/3 (file index = 2)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Dec_24_to_Feb_25-2-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      " \n",
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "ddp.download_files0(API_KEY, url25, \"C:/Users/rf2694\",\n",
    "                    start_date = '2025-01-01', end_date = '2025-01-31', skip_exists=True) #be sure to change the directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511ceafc-7b9c-46df-bc2f-d2a4f4a8a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brief tutorial on glob: https://www.geeksforgeeks.org/how-to-use-glob-function-to-find-files-recursively-in-python/\n",
    "#code reference: https://python.plainenglish.io/glob-and-pandas-working-in-unison-304242627e78\n",
    "frame = []\n",
    "for name in glob.glob('Neighborhood_Patterns_NY_Dec_24_to_Feb_25*'):\n",
    "    frame.append(pd.read_csv(name, usecols=['AREA','STOPS_BY_EACH_HOUR','POPULARITY_BY_EACH_HOUR','STOPS_BY_DAY','DATE_RANGE_START','DATE_RANGE_END']))\n",
    "\n",
    "data25 = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76e87c5-b0d6-4114-a222-5349370ae1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = []\n",
    "for name in glob.glob('Neighborhood_Patterns_NY_Jan_24*'):\n",
    "    frame.append(pd.read_csv(name, usecols=['AREA','STOPS_BY_EACH_HOUR','POPULARITY_BY_EACH_HOUR','STOPS_BY_DAY','DATE_RANGE_START','DATE_RANGE_END']))\n",
    "\n",
    "data24 = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e948c-a685-4409-b5e5-58b50a578a97",
   "metadata": {},
   "source": [
    "## Defining the Congestion Pricing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f78930-7eb4-4fd2-bb96-29183bcca7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360610050004</td>\n",
       "      <td>POLYGON ((-73.98878 40.73397, -73.98829 40.734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360610044007</td>\n",
       "      <td>POLYGON ((-73.98202 40.73201, -73.98156 40.732...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360610063004</td>\n",
       "      <td>POLYGON ((-73.99919 40.73413, -73.99902 40.734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360610064005</td>\n",
       "      <td>POLYGON ((-73.9809 40.73789, -73.9785 40.73679...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID                                           geometry\n",
       "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...\n",
       "1  360610050004  POLYGON ((-73.98878 40.73397, -73.98829 40.734...\n",
       "2  360610044007  POLYGON ((-73.98202 40.73201, -73.98156 40.732...\n",
       "3  360610063004  POLYGON ((-73.99919 40.73413, -73.99902 40.734...\n",
       "4  360610064005  POLYGON ((-73.9809 40.73789, -73.9785 40.73679..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#geopandas & read zip file with QGIS output\n",
    "import geopandas as gp #install if needed\n",
    "crzone = gp.read_file(\"zip:///Users/rf2694/Documents/QGIS/crz2019.zip\")[['GEOID','geometry']] #modify file path to locate congestion zone shapefile\n",
    "crzone = crzone.astype({'GEOID': 'int64'}) #for merging purposes\n",
    "crzone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296bc2b1-ad79-4965-961b-5e66f199f0bf",
   "metadata": {},
   "source": [
    "## Limiting Data to the Congestion Pricing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7abccf63-c0d9-4314-93f3-1f2219846044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas merge to filter Dewey data by CZ GEOID (function also works for geopandas)\n",
    "#reference for pandas merge: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html\n",
    "bigData25 = crzone.merge(right=data25, left_on='GEOID', right_on='AREA')\n",
    "bigData24 = crzone.merge(right=data24, how='left', left_on='GEOID', right_on='AREA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cab00e-19db-4a93-8cce-0c41ed9b6a8c",
   "metadata": {},
   "source": [
    "## Stops by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36940253-5d87-4d42-bbfb-1a4d9409916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          GEOID                                           geometry  \\\n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "\n",
      "         DATE  STOPS_BY_DAY  \n",
      "0  2025-01-01           142  \n",
      "0  2025-01-02           222  \n",
      "0  2025-01-03           160  \n",
      "0  2025-01-04            44  \n",
      "0  2025-01-05           100  \n",
      "0  2025-01-06            60  \n",
      "0  2025-01-07           101  \n",
      "0  2025-01-08            76  \n",
      "0  2025-01-09            57  \n",
      "0  2025-01-10           117  \n",
      "0  2025-01-11           163  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rf2694\\AppData\\Local\\anaconda3\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "#STOPS BY DAY DATASET (2025)\n",
    "dataByDay25 = bigData25[[\"GEOID\",\"geometry\",\"DATE_RANGE_START\",\"DATE_RANGE_END\",\"STOPS_BY_DAY\"]]\n",
    "#dataByDay25 = dataByDay25.dropna()\n",
    "dataByDay25['STOPS_BY_DAY'] = dataByDay25['STOPS_BY_DAY'].apply(literal_eval) #changes type from string to actual list lol\n",
    "dataByDate25 = dataByDay25.explode('STOPS_BY_DAY') #boom!\n",
    "\n",
    "day25 = pd.date_range(start=bigData25['DATE_RANGE_START'][0], end=bigData25['DATE_RANGE_END'][0]).strftime(\"%Y-%m-%d\").tolist()\n",
    "day25 = day25[0:31] #every date in january 2025, not including feb 1\n",
    "dates25 = day25 * len(dataByDay25)\n",
    "dataByDate25['DATE']=dates25\n",
    "dataByDateClean25 = dataByDate25[[\"GEOID\",\"geometry\",\"DATE\", \"STOPS_BY_DAY\"]]\n",
    "dataByDateClean25 = dataByDateClean25.astype({'STOPS_BY_DAY': 'int64'})\n",
    "print(dataByDateClean25[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a8eb4eb-51c2-42a6-90dc-67a8b7a3223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rf2694\\AppData\\Local\\Temp\\ipykernel_10320\\926012306.py:3: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  dataByDateClean25.to_file(\"J25_daily.shp\")\n",
      "C:\\Users\\rf2694\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'STOPS_BY_DAY' to 'STOPS_BY_D'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "#write to shapefile\n",
    "#note that variable names >10 characters will get cut off. just rename in QGIS idk\n",
    "dataByDateClean25.to_file(\"J25_daily.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55364bff-4000-4d8a-9780-021990ed8841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          GEOID                                           geometry  \\\n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...   \n",
      "\n",
      "         DATE  STOPS_BY_DAY  \n",
      "0  2024-01-01            83  \n",
      "0  2024-01-02           205  \n",
      "0  2024-01-03           220  \n",
      "0  2024-01-04           246  \n",
      "0  2024-01-05           198  \n",
      "0  2024-01-06            79  \n",
      "0  2024-01-07            80  \n",
      "0  2024-01-08           167  \n",
      "0  2024-01-09            80  \n",
      "0  2024-01-10            96  \n",
      "0  2024-01-11           186  \n"
     ]
    }
   ],
   "source": [
    "#STOPS BY DAY DATASET (2024)\n",
    "dataByDay24 = bigData24[[\"GEOID\",\"geometry\",\"DATE_RANGE_START\",\"DATE_RANGE_END\",\"STOPS_BY_DAY\"]]\n",
    "dataByDay24 = dataByDay24.dropna()\n",
    "dataByDay24['STOPS_BY_DAY'] = dataByDay24['STOPS_BY_DAY'].apply(literal_eval) #changes type from string to actual list lol\n",
    "dataByDate24 = dataByDay24.explode('STOPS_BY_DAY') #boom!\n",
    "\n",
    "day24 = pd.date_range(start=bigData24['DATE_RANGE_START'][0], end=bigData24['DATE_RANGE_END'][0]).strftime(\"%Y-%m-%d\").tolist()\n",
    "day24 = day24[0:31] #every date in january 2024, not including feb 1\n",
    "dates24 = day24 * len(dataByDay24)\n",
    "dataByDate24['DATE']=dates24\n",
    "dataByDateClean24 = dataByDate24[[\"GEOID\",\"geometry\",\"DATE\", \"STOPS_BY_DAY\"]]\n",
    "dataByDateClean24 = dataByDateClean24.astype({'STOPS_BY_DAY': 'int64'})\n",
    "print(dataByDateClean24[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d6015af-6d11-4292-8093-64e758abf6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rf2694\\AppData\\Local\\Temp\\ipykernel_10320\\2719369358.py:3: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  dataByDateClean24.to_file(\"J24_daily.shp\")\n",
      "C:\\Users\\rf2694\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'STOPS_BY_DAY' to 'STOPS_BY_D'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "#write to shapefile\n",
    "#note that variable names >10 characters will get cut off. just rename in QGIS idk\n",
    "dataByDateClean24.to_file(\"J24_daily.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51155186-3e0b-4abf-9eb0-b9f2eae3863f",
   "metadata": {},
   "source": [
    "## General Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b422f4e-84e4-4bfa-aed4-3627f51c72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex to make slicing feasible\n",
    "#indices were likely messed up by exploding previously\n",
    "new_index = range(0,len(dataByDateClean24))\n",
    "dataByDateClean24.index = new_index\n",
    "\n",
    "new_index = range(0,len(dataByDateClean25))\n",
    "dataByDateClean25.index = new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "931535c6-2685-4e06-bde1-ca572a8a2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataByDateClean25['DATE'] = pd.to_datetime(dataByDateClean25['DATE'], format='%Y-%m-%d')\n",
    "dataByDateClean24['DATE'] = pd.to_datetime(dataByDateClean24['DATE'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9cab5fd8-88b5-4344-9dd3-73211e902756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>DATE</th>\n",
       "      <th>STOPS_BY_DAY</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>83</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>205</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>220</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>246</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>198</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID                                           geometry       DATE  \\\n",
       "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748... 2024-01-01   \n",
       "1  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748... 2024-01-02   \n",
       "2  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748... 2024-01-03   \n",
       "3  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748... 2024-01-04   \n",
       "4  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748... 2024-01-05   \n",
       "\n",
       "   STOPS_BY_DAY        dow  \n",
       "0            83     Monday  \n",
       "1           205    Tuesday  \n",
       "2           220  Wednesday  \n",
       "3           246   Thursday  \n",
       "4           198     Friday  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add day of week\n",
    "weekday = []\n",
    "for i in range(0,len(dataByDateClean24)):\n",
    "    weekday += [dataByDateClean24['DATE'][i].strftime('%A')]\n",
    "\n",
    "dataByDateClean24['dow'] = weekday\n",
    "dataByDateClean24.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ceb06246-ced8-449d-bf27-ba8b5d1a3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add day of week\n",
    "weekday = []\n",
    "for i in range(0,len(dataByDateClean25)):\n",
    "    weekday += [dataByDateClean25['DATE'][i].strftime('%A')]\n",
    "\n",
    "dataByDateClean25['dow'] = weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8748fdc-4010-4127-a441-cc68550197af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates \"day\" category to specify day separate from year for later merging\n",
    "#reference: https://stackoverflow.com/questions/39908314/slice-all-strings-in-a-list\n",
    "dataByDateClean25 = dataByDateClean25.astype({'DATE': 'string'})\n",
    "dataByDateClean25['day']= [word[5:] for word in dataByDateClean25['DATE']]\n",
    "dataByDateClean24 = dataByDateClean24.astype({'DATE': 'string'})\n",
    "dataByDateClean24['day']= [word[5:] for word in dataByDateClean24['DATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9de186db-34df-4ffc-b367-e6632a3a0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove zeroes (rows with no stops or data)\n",
    "dataByDateClean24 = dataByDateClean24[dataByDateClean24['STOPS_BY_DAY'] != 0]\n",
    "dataByDateClean25 = dataByDateClean25[dataByDateClean25['STOPS_BY_DAY'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78f2b787-5564-45a2-89be-5429f0fb79e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>geom</th>\n",
       "      <th>day</th>\n",
       "      <th>stops25</th>\n",
       "      <th>stops24</th>\n",
       "      <th>dow25</th>\n",
       "      <th>dow24</th>\n",
       "      <th>percchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "      <td>01-01</td>\n",
       "      <td>142</td>\n",
       "      <td>83</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>71.084337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "      <td>01-02</td>\n",
       "      <td>222</td>\n",
       "      <td>205</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8.292683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "      <td>01-03</td>\n",
       "      <td>160</td>\n",
       "      <td>220</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>-27.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "      <td>01-04</td>\n",
       "      <td>44</td>\n",
       "      <td>246</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>-82.113821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360610078001</td>\n",
       "      <td>POLYGON ((-73.97584 40.74886, -73.97497 40.748...</td>\n",
       "      <td>01-05</td>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Friday</td>\n",
       "      <td>-49.494949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID                                               geom    day  \\\n",
       "0  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...  01-01   \n",
       "1  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...  01-02   \n",
       "2  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...  01-03   \n",
       "3  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...  01-04   \n",
       "4  360610078001  POLYGON ((-73.97584 40.74886, -73.97497 40.748...  01-05   \n",
       "\n",
       "   stops25  stops24      dow25      dow24  percchange  \n",
       "0      142       83  Wednesday     Monday   71.084337  \n",
       "1      222      205   Thursday    Tuesday    8.292683  \n",
       "2      160      220     Friday  Wednesday  -27.272727  \n",
       "3       44      246   Saturday   Thursday  -82.113821  \n",
       "4      100      198     Sunday     Friday  -49.494949  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average per day per zone and clean things up\n",
    "#https://stackoverflow.com/questions/53549492/joining-two-pandas-dataframes-based-on-multiple-conditions\n",
    "zoneavg = dataByDateClean25.merge(dataByDateClean24, how='inner', on=['GEOID','day'])\n",
    "zoneavg = zoneavg[['GEOID','geometry_x','day','STOPS_BY_DAY_x','STOPS_BY_DAY_y','dow_x','dow_y']]\n",
    "zoneavg = zoneavg.rename(columns={'STOPS_BY_DAY_x':'stops25','STOPS_BY_DAY_y':'stops24','geometry_x':'geom','dow_x':'dow25','dow_y':'dow24'})\n",
    "zoneavg['percchange'] = zoneavg['stops25']/zoneavg['stops24']*100 -100\n",
    "zoneavg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5865b8f8-9fe9-4350-a88b-6f4e83b505b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set weekend/weekday\n",
    "day25 = []\n",
    "day24 = []\n",
    "for i in range(0,len(zoneavg)):\n",
    "    if zoneavg['dow25'][i] in ['Saturday', 'Sunday']:\n",
    "        day25 += ['weekend']\n",
    "    else:\n",
    "            day25 += ['weekday']\n",
    "    if zoneavg['dow24'][i] in ['Saturday', 'Sunday']:\n",
    "            day24 += ['weekend']\n",
    "    else:\n",
    "            day24 += ['weekday']\n",
    "\n",
    "zoneavg['day25'] = day25\n",
    "zoneavg['day24'] = day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1ff67798-8de7-4671-8789-a08697ce39b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rf2694\\AppData\\Local\\Temp\\ipykernel_10320\\2468443686.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zones24.rename(columns={'day24':'day'},inplace=True)\n",
      "C:\\Users\\rf2694\\AppData\\Local\\Temp\\ipykernel_10320\\2468443686.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zones25.rename(columns={'day25':'day'},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#for better comparison by weekend/weekday rather than specific date, make two datasets\n",
    "zones24 = zoneavg[['GEOID','geom','stops24','dow24','day24']]\n",
    "zones24.rename(columns={'day24':'day'},inplace=True)\n",
    "zones25 = zoneavg[['GEOID','geom','stops25','dow25','day25']]\n",
    "zones25.rename(columns={'day25':'day'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd2e9518-3e49-4133-9486-ee5f44ce8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total stops in each zone\n",
    "ztotal24 = zones24.groupby(by=['GEOID'])['stops24'].sum()\n",
    "ztotal24.to_csv(\"zonetotal_24.csv\")\n",
    "\n",
    "ztotal25 = zones25.groupby(by=['GEOID'])['stops25'].sum()\n",
    "ztotal25.to_csv(\"zonetotal_25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9f313734-eec2-4deb-8776-9944ef311883",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalChangeZoned = ztotal25/ztotal24\n",
    "totalChangeZoned.to_csv('totalchange.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80bf2235-eda0-461a-83f2-3484ea99a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoneavgClean = zoneavg[(zoneavg.stops24 != 0) & (zoneavg.stops25 != 0)] #removes values of -100% change and inf (both issues with missing values)\n",
    "zoneavgClean.to_file(\"zonechangesClean.shp\")\n",
    "zoneavgClean.to_csv(\"zonechangesClean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7798df-59e1-4e34-974f-f8f8b8b7fb9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Depreciated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf053ad0-d818-44bc-b250-fc895812c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods for filtering: https://www.kdnuggets.com/2022/12/five-ways-conditional-filtering-pandas.html\n",
    "filteredbigDataUS = bigDataUS\n",
    "filteredbigDataUS['DATE_RANGE_START'] = pd.to_datetime(bigDataUS['DATE_RANGE_START'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "filteredbigDataUS['DATE_RANGE_END'] = pd.to_datetime(bigDataUS['DATE_RANGE_END'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "filteredbigDataUS = filteredbigDataUS.query('GEOID.between(360610000000,360620000000) and DATE_RANGE_START >= \"2025-01-01\"')\n",
    "filteredbigDataUS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954cef1-16c9-44e9-b753-62710084271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOPS BY DAY DATASET (Filtered from US)\n",
    "dataByDayUS = filteredbigDataUS[[\"GEOID\",\"geometry\",\"DATE_RANGE_START\",\"DATE_RANGE_END\",\"STOPS_BY_DAY\"]]\n",
    "dataByDayUS = dataByDayUS.dropna()\n",
    "dataByDayUS['STOPS_BY_DAY'] = dataByDayUS['STOPS_BY_DAY'].apply(literal_eval) #changes type from string to actual list lol\n",
    "dataByDateUS = dataByDayUS.explode('STOPS_BY_DAY') #boom!\n",
    "\n",
    "dayUS = pd.date_range(start=bigDataUS['DATE_RANGE_START'][2], end=filteredbigDataUS['DATE_RANGE_END'][2]).strftime(\"%Y-%m-%d\").tolist()\n",
    "dayUS = dayUS[0:31] #every date in january 2025, not including feb 1\n",
    "datesUS = dayUS * len(dataByDayUS)\n",
    "dataByDateUS['DATE']=datesUS\n",
    "dataByDateCleanUS = dataByDateUS[[\"GEOID\",\"geometry\",\"DATE\", \"STOPS_BY_DAY\"]]\n",
    "dataByDateCleanUS = dataByDateCleanUS.astype({'STOPS_BY_DAY': 'int64'})\n",
    "print(dataByDateCleanUS[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcedaf4-e3b7-4d53-9d4c-31bc3682962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOPS BY DAY DATASET (merged with NY block group map)\n",
    "filteredbigDataNY = bigDataNY\n",
    "filteredbigDataNY['DATE_RANGE_START'] = pd.to_datetime(bigDataNY['DATE_RANGE_START'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "filteredbigDataNY['DATE_RANGE_END'] = pd.to_datetime(bigDataNY['DATE_RANGE_END'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "filteredbigDataNY = filteredbigDataNY.query('GEOID.between(360610000000,360620000000) and DATE_RANGE_START >= \"2024-12-01\"')\n",
    "\n",
    "dataByDayNY = filteredbigDataNY[[\"GEOID\",\"geometry\",\"DATE_RANGE_START\",\"DATE_RANGE_END\",\"STOPS_BY_DAY\"]]\n",
    "dataByDayNY = dataByDayNY.dropna()\n",
    "dataByDayNY['STOPS_BY_DAY'] = dataByDayNY['STOPS_BY_DAY'].apply(literal_eval) #changes type from string to actual list lol\n",
    "dataByDateNY = dataByDayNY.explode('STOPS_BY_DAY') #boom!\n",
    "\n",
    "dayNY = pd.date_range(start=filteredbigDataNY['DATE_RANGE_START'][3697], end=filteredbigDataNY['DATE_RANGE_END'][3697]).strftime(\"%Y-%m-%d\").tolist()\n",
    "dayNY = dayNY[0:31] #every date in january 2025, not including feb 1\n",
    "datesNY = dayNY * len(dataByDayNY)\n",
    "dataByDateNY['DATE']=datesNY\n",
    "dataByDateCleanNY = dataByDateNY[[\"GEOID\",\"geometry\",\"DATE\", \"STOPS_BY_DAY\"]]\n",
    "dataByDateCleanNY = dataByDateCleanNY.astype({'STOPS_BY_DAY': 'int64'})\n",
    "print(dataByDateCleanNY[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c41039-8638-4ffa-a266-0c2404661c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to get day by day weather data to reduce differences (thanks Dane)\n",
    "#url = 'https://www.wunderground.com/history/monthly/us/ny/new-york-city/KLGA/date/2025-1'\n",
    "#html = requests.get(url).content\n",
    "df_list = pd.read_html(\"weather24.htm\")\n",
    "df = df_list[-1]\n",
    "print(df)\n",
    "df.to_csv('my data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f10f07-1bb0-455e-b1e6-c93a3ff31516",
   "metadata": {},
   "source": [
    "### Spend Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a1206-a777-47cf-93d6-dddfe126a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlSpend = f\"https://app.deweydata.io/external-api/v3/products/eb6e748a-0fdd-4bc7-9dd7-bbed0890948d/files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8db51c-5907-48ec-9546-25a728bac1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddp.download_files0(API_KEY, urlSpend, \"C:/Users/rf2694\",\n",
    "                    start_date = '2024-01-01', end_date = '2024-01-31', skip_exists=True) #be sure to change the directory!\n",
    "#ddp.download_files0(API_KEY, urlSpend, \"C:/Users/rf2694\", start_date = '2025-01-01', end_date = '2025-01-31', skip_exists=True) #be sure to change the directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852a070-b6ff-405a-85b5-f6d89d73bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = []\n",
    "for name in glob.glob('Spend_Patterns_Entire_US-?-SPEND_DATE_RANGE_START-2024*'):\n",
    "    frame.append(pd.read_csv(name, usecols=['PLACEKEY','LOCATION_NAME','POPULARITY_BY_EACH_HOUR','SPEND_BY_DAY','SPEND_DATE_RANGE_START','SPEND_DATE_RANGE_END']))\n",
    "\n",
    "spend24 = pd.concat(frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
