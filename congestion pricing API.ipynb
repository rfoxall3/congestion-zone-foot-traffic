{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38097974-5144-4382-a852-e1681e07b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up API backend and useful packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from ast import literal_eval\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0eea6c-1f03-4ccc-bd41-527f3d9a1db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement git (from versions: none)\n",
      "ERROR: No matching distribution found for git\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/Dewey-Data/deweydatapy.git #installs Dewey Data package for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c911f08-38a6-456b-a256-fbfed3870fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deweydatapy as ddp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c352cc-09d6-44c9-8848-bd591eaceb02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d182c3-4d33-4435-b907-aa92920d6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#individual key (get your own!)\n",
    "API_KEY = '7LQsijkY.KX88klG0wxYG3kNa7P4sgWDHLJaf2czgQTtR3PDb39mfCoX9S9PHit3B'\n",
    "#dec 24 to feb 25\n",
    "url25 = f\"https://app.deweydata.io/external-api/v3/products/ff6af5ab-fe02-4ea3-9a24-5fad03700b38/files\"\n",
    "#jan 24\n",
    "url24 = f\"https://app.deweydata.io/external-api/v3/products/712cd497-9ff8-45a6-b15b-b14ea3ba5146/files\"\n",
    "\n",
    "urlUS = f\"https://app.deweydata.io/external-api/v3/products/393e1d09-e017-444c-896c-fbc154176009/files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55bdbd1c-6c24-4c05-b403-e1e0897107ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting files information for page 1/1...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 1\n",
      "Total number of files: 3\n",
      "Total files size (MB): 545.79\n",
      "Average single file size (MB): 181.93\n",
      "Date partition column: DATE_RANGE_START\n",
      "Expires at: 2025-02-22T19:08:56.493Z\n",
      "-----------------------------------------------------------------\n",
      "Start downloading...\n",
      " \n",
      "Downloading 1/3 (file index = 0)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Jan_24-0-DATE_RANGE_START-2024-01-01.csv\n",
      "Skipping...\n",
      "Downloading 2/3 (file index = 1)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Jan_24-1-DATE_RANGE_START-2024-01-01.csv\n",
      "Skipping...\n",
      "Downloading 3/3 (file index = 2)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Jan_24-2-DATE_RANGE_START-2024-01-01.csv\n",
      "Skipping...\n",
      " \n",
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "ddp.download_files0(API_KEY, url24, \"C:/Users/rf2694\",\n",
    "                    start_date = '2024-01-01', end_date = '2024-01-31', skip_exists=True) #be sure to change the directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea8eab55-5ad6-4ca6-b3e2-9ccd62bfeea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting files information for page 1/1...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 1\n",
      "Total number of files: 3\n",
      "Total files size (MB): 437.46\n",
      "Average single file size (MB): 145.82\n",
      "Date partition column: DATE_RANGE_START\n",
      "Expires at: 2025-02-22T19:09:59.686Z\n",
      "-----------------------------------------------------------------\n",
      "Start downloading...\n",
      " \n",
      "Downloading 1/3 (file index = 0)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Dec_24_to_Feb_25-0-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 2/3 (file index = 1)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Dec_24_to_Feb_25-1-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 3/3 (file index = 2)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_NY_Dec_24_to_Feb_25-2-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      " \n",
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "ddp.download_files0(API_KEY, url25, \"C:/Users/rf2694\",\n",
    "                    start_date = '2025-01-01', end_date = '2025-01-31', skip_exists=True) #be sure to change the directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae503e48-11fc-4e4b-ba10-b43184825ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting files information for page 1/1...\n",
      "Files information collection completed.\n",
      " \n",
      "Files information summary ---------------------------------------\n",
      "Total number of pages: 1\n",
      "Total number of files: 38\n",
      "Total files size (MB): 7,822.34\n",
      "Average single file size (MB): 205.85\n",
      "Date partition column: DATE_RANGE_START\n",
      "Expires at: 2025-02-22T19:10:46.012Z\n",
      "-----------------------------------------------------------------\n",
      "Start downloading...\n",
      " \n",
      "Downloading 1/38 (file index = 0)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-0-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 2/38 (file index = 1)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-1-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 3/38 (file index = 2)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-2-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 4/38 (file index = 3)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-3-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 5/38 (file index = 4)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-4-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 6/38 (file index = 5)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-5-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 7/38 (file index = 6)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-6-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 8/38 (file index = 7)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-7-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 9/38 (file index = 8)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-8-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 10/38 (file index = 9)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-9-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 11/38 (file index = 10)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-10-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 12/38 (file index = 11)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-11-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 13/38 (file index = 12)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-12-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 14/38 (file index = 13)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-13-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 15/38 (file index = 14)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-14-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 16/38 (file index = 15)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-15-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 17/38 (file index = 16)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-16-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 18/38 (file index = 17)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-17-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 19/38 (file index = 18)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-18-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 20/38 (file index = 19)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-19-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 21/38 (file index = 20)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-20-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 22/38 (file index = 21)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-21-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 23/38 (file index = 22)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-22-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 24/38 (file index = 23)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-23-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 25/38 (file index = 24)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-24-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 26/38 (file index = 25)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-25-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 27/38 (file index = 26)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-26-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 28/38 (file index = 27)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-27-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 29/38 (file index = 28)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-28-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 30/38 (file index = 29)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-29-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 31/38 (file index = 30)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-30-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 32/38 (file index = 31)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-31-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 33/38 (file index = 32)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-32-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 34/38 (file index = 33)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-33-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 35/38 (file index = 34)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-34-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 36/38 (file index = 35)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-35-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 37/38 (file index = 36)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-36-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      "Downloading 38/38 (file index = 37)\n",
      "File already exists: C:/Users/rf2694/Neighborhood_Patterns_US_Jan_25_-37-DATE_RANGE_START-2025-01-01.csv\n",
      "Skipping...\n",
      " \n",
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "ddp.download_files0(API_KEY, urlUS, \"C:/Users/rf2694\",\n",
    "                    start_date = '2025-01-01', end_date = '2025-01-31', skip_exists=True) #be sure to change the directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "511ceafc-7b9c-46df-bc2f-d2a4f4a8a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brief tutorial on glob: https://www.geeksforgeeks.org/how-to-use-glob-function-to-find-files-recursively-in-python/\n",
    "#code reference: https://python.plainenglish.io/glob-and-pandas-working-in-unison-304242627e78\n",
    "frame = []\n",
    "for name in glob.glob('Neighborhood_Patterns_NY_Dec_24_to_Feb_25*'):\n",
    "    frame.append(pd.read_csv(name, usecols=['AREA','STOPS_BY_EACH_HOUR','POPULARITY_BY_EACH_HOUR','STOPS_BY_DAY','DATE_RANGE_START','DATE_RANGE_END']))\n",
    "\n",
    "data25 = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c76e87c5-b0d6-4114-a222-5349370ae1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = []\n",
    "for name in glob.glob('Neighborhood_Patterns_NY_Jan_24*'):\n",
    "    frame.append(pd.read_csv(name, usecols=['AREA','STOPS_BY_EACH_HOUR','POPULARITY_BY_EACH_HOUR','STOPS_BY_DAY','DATE_RANGE_START','DATE_RANGE_END']))\n",
    "\n",
    "data24 = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "913c38a9-6719-40f5-a83a-d5f4a1c6fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = []\n",
    "for name in glob.glob('Neighborhood_Patterns_US*'):\n",
    "    frame.append(pd.read_csv(name, usecols=['AREA','STOPS_BY_EACH_HOUR','POPULARITY_BY_EACH_HOUR','STOPS_BY_DAY','DATE_RANGE_START','DATE_RANGE_END']))\n",
    "\n",
    "dataUS = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e948c-a685-4409-b5e5-58b50a578a97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Defining the Congestion Pricing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40f78930-7eb4-4fd2-bb96-29183bcca7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360610080005</td>\n",
       "      <td>POLYGON ((990301.416 213054.566, 990434.901 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360610012003</td>\n",
       "      <td>POLYGON ((989469.994 199908.568, 989550.62 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360610024002</td>\n",
       "      <td>POLYGON ((991260.962 202278.262, 991277.847 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360610010021</td>\n",
       "      <td>POLYGON ((989803.856 200714.542, 989936.558 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360610065003</td>\n",
       "      <td>POLYGON ((983481.705 204668.73, 983554.328 204...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID                                           geometry\n",
       "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...\n",
       "1  360610012003  POLYGON ((989469.994 199908.568, 989550.62 200...\n",
       "2  360610024002  POLYGON ((991260.962 202278.262, 991277.847 20...\n",
       "3  360610010021  POLYGON ((989803.856 200714.542, 989936.558 20...\n",
       "4  360610065003  POLYGON ((983481.705 204668.73, 983554.328 204..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#geopandas & read zip file with QGIS output\n",
    "import geopandas as gp #install if needed\n",
    "crzone = gp.read_file(\"zip:///Users/rf2694/Documents/QGIS/crzone shapefiles.zip\")[['GEOID','geometry']]\n",
    "crzone = crzone.astype({'GEOID': 'int64'}) #for merging purposes\n",
    "crzone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296bc2b1-ad79-4965-961b-5e66f199f0bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Limiting Data to the Congestion Pricing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7abccf63-c0d9-4314-93f3-1f2219846044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          GEOID                                           geometry  \\\n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "1  360610012003  POLYGON ((989469.994 199908.568, 989550.62 200...   \n",
      "2  360610024002  POLYGON ((991260.962 202278.262, 991277.847 20...   \n",
      "3  360610010021  POLYGON ((989803.856 200714.542, 989936.558 20...   \n",
      "4  360610065003  POLYGON ((983481.705 204668.73, 983554.328 204...   \n",
      "\n",
      "           AREA         DATE_RANGE_START           DATE_RANGE_END  \\\n",
      "0  3.606101e+11  2024-01-01 00:00:00.000  2024-02-01 00:00:00.000   \n",
      "1  3.606100e+11  2024-01-01 00:00:00.000  2024-02-01 00:00:00.000   \n",
      "2  3.606100e+11  2024-01-01 00:00:00.000  2024-02-01 00:00:00.000   \n",
      "3  3.606100e+11  2024-01-01 00:00:00.000  2024-02-01 00:00:00.000   \n",
      "4  3.606101e+11  2024-01-01 00:00:00.000  2024-02-01 00:00:00.000   \n",
      "\n",
      "                                        STOPS_BY_DAY  \\\n",
      "0  [199,164,117,165,269,58,98,228,264,198,260,286...   \n",
      "1  [83,139,223,187,201,101,102,80,42,83,198,139,1...   \n",
      "2  [22,39,98,81,122,36,0,21,16,24,55,42,17,41,0,7...   \n",
      "3  [340,303,241,349,409,164,177,327,321,264,287,1...   \n",
      "4  [306,160,157,165,323,143,244,308,182,164,387,3...   \n",
      "\n",
      "                                  STOPS_BY_EACH_HOUR  \\\n",
      "0  [41,45,21,18,0,0,0,0,0,0,0,0,0,23,0,0,25,21,0,...   \n",
      "1  [25,0,0,0,0,0,0,0,0,0,0,0,0,22,0,0,18,20,0,0,0...   \n",
      "2  [18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
      "3  [37,17,0,0,16,24,0,37,0,0,0,0,0,15,37,40,20,42...   \n",
      "4  [78,17,63,0,0,0,0,0,0,0,0,0,0,0,55,16,42,0,17,...   \n",
      "\n",
      "                             POPULARITY_BY_EACH_HOUR  \n",
      "0  [38,60,43,36,19,18,18,20,24,17,22,24,25,42,19,...  \n",
      "1  [22,20,16,23,25,23,18,19,20,17,17,15,23,36,22,...  \n",
      "2  [20,21,25,20,18,20,17,21,15,24,24,22,23,15,25,...  \n",
      "3  [16,36,38,39,64,63,59,85,78,84,64,57,36,55,57,...  \n",
      "4  [77,39,38,21,0,0,0,0,0,0,0,0,0,0,60,21,43,0,24...  \n"
     ]
    }
   ],
   "source": [
    "#next steps:\n",
    "#use pandas merge to filter Dewey data by CZ GEOID\n",
    "#tips for pandas merge: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html\n",
    "bigData25 = crzone.merge(right=data25, left_on='GEOID', right_on='AREA')\n",
    "bigData24 = crzone.merge(right=data24, how='left', left_on='GEOID', right_on='AREA')\n",
    "\n",
    "print(bigData24.head())\n",
    "\n",
    "bigDataUS = crzone.merge(right=dataUS, how='left', left_on='GEOID', right_on='AREA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "427e52af-0094-4db7-b022-7cc553dd798c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>AREA</th>\n",
       "      <th>DATE_RANGE_START</th>\n",
       "      <th>DATE_RANGE_END</th>\n",
       "      <th>STOPS_BY_DAY</th>\n",
       "      <th>STOPS_BY_EACH_HOUR</th>\n",
       "      <th>POPULARITY_BY_EACH_HOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360610080005</td>\n",
       "      <td>POLYGON ((990301.416 213054.566, 990434.901 21...</td>\n",
       "      <td>3.606101e+11</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>[80,85,58,118,64,79,121,124,140,41,104,164,96,...</td>\n",
       "      <td>[15,0,19,0,0,0,0,0,0,0,0,0,0,0,23,0,0,25,0,0,0...</td>\n",
       "      <td>[22,0,19,0,0,0,0,0,0,0,0,0,0,0,21,22,0,16,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360610080005</td>\n",
       "      <td>POLYGON ((990301.416 213054.566, 990434.901 21...</td>\n",
       "      <td>3.606101e+11</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>[80,85,58,118,64,79,121,124,140,41,104,164,96,...</td>\n",
       "      <td>[15,0,19,0,0,0,0,0,0,0,0,0,0,0,23,0,0,25,0,0,0...</td>\n",
       "      <td>[22,0,19,0,0,0,0,0,0,0,0,0,0,0,21,22,0,16,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>360610012003</td>\n",
       "      <td>POLYGON ((989469.994 199908.568, 989550.62 200...</td>\n",
       "      <td>3.606100e+11</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>[0,56,65,20,0,106,16,41,105,37,56,16,43,0,0,10...</td>\n",
       "      <td>[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...</td>\n",
       "      <td>[39,38,40,43,39,37,38,38,45,37,35,35,38,43,35,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>360610012003</td>\n",
       "      <td>POLYGON ((989469.994 199908.568, 989550.62 200...</td>\n",
       "      <td>3.606100e+11</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>[0,56,65,20,0,106,16,41,105,37,56,16,43,0,0,10...</td>\n",
       "      <td>[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...</td>\n",
       "      <td>[39,38,40,43,39,37,38,38,45,37,35,35,38,43,35,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>360610024002</td>\n",
       "      <td>POLYGON ((991260.962 202278.262, 991277.847 20...</td>\n",
       "      <td>3.606100e+11</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>[15,16,17,20,0,35,35,0,0,0,0,0,65,23,23,15,55,...</td>\n",
       "      <td>[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,...</td>\n",
       "      <td>[23,19,20,17,22,16,18,20,18,0,0,0,0,0,0,0,22,2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID                                           geometry  \\\n",
       "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
       "3  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
       "5  360610012003  POLYGON ((989469.994 199908.568, 989550.62 200...   \n",
       "7  360610012003  POLYGON ((989469.994 199908.568, 989550.62 200...   \n",
       "9  360610024002  POLYGON ((991260.962 202278.262, 991277.847 20...   \n",
       "\n",
       "           AREA DATE_RANGE_START DATE_RANGE_END  \\\n",
       "2  3.606101e+11       2025-01-01     2025-02-01   \n",
       "3  3.606101e+11       2025-01-01     2025-02-01   \n",
       "5  3.606100e+11       2025-01-01     2025-02-01   \n",
       "7  3.606100e+11       2025-01-01     2025-02-01   \n",
       "9  3.606100e+11       2025-01-01     2025-02-01   \n",
       "\n",
       "                                        STOPS_BY_DAY  \\\n",
       "2  [80,85,58,118,64,79,121,124,140,41,104,164,96,...   \n",
       "3  [80,85,58,118,64,79,121,124,140,41,104,164,96,...   \n",
       "5  [0,56,65,20,0,106,16,41,105,37,56,16,43,0,0,10...   \n",
       "7  [0,56,65,20,0,106,16,41,105,37,56,16,43,0,0,10...   \n",
       "9  [15,16,17,20,0,35,35,0,0,0,0,0,65,23,23,15,55,...   \n",
       "\n",
       "                                  STOPS_BY_EACH_HOUR  \\\n",
       "2  [15,0,19,0,0,0,0,0,0,0,0,0,0,0,23,0,0,25,0,0,0...   \n",
       "3  [15,0,19,0,0,0,0,0,0,0,0,0,0,0,23,0,0,25,0,0,0...   \n",
       "5  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...   \n",
       "7  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...   \n",
       "9  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,...   \n",
       "\n",
       "                             POPULARITY_BY_EACH_HOUR  \n",
       "2  [22,0,19,0,0,0,0,0,0,0,0,0,0,0,21,22,0,16,0,0,...  \n",
       "3  [22,0,19,0,0,0,0,0,0,0,0,0,0,0,21,22,0,16,0,0,...  \n",
       "5  [39,38,40,43,39,37,38,38,45,37,35,35,38,43,35,...  \n",
       "7  [39,38,40,43,39,37,38,38,45,37,35,35,38,43,35,...  \n",
       "9  [23,19,20,17,22,16,18,20,18,0,0,0,0,0,0,0,22,2...  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#methods for filtering: https://www.kdnuggets.com/2022/12/five-ways-conditional-filtering-pandas.html\n",
    "filteredbigDataUS = bigDataUS\n",
    "filteredbigDataUS['DATE_RANGE_START'] = pd.to_datetime(bigDataUS['DATE_RANGE_START'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "filteredbigDataUS['DATE_RANGE_END'] = pd.to_datetime(bigDataUS['DATE_RANGE_END'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "filteredbigDataUS = filteredbigDataUS.query('GEOID.between(360610000000,360620000000) and DATE_RANGE_START >= \"2025-01-01\"')\n",
    "filteredbigDataUS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cab00e-19db-4a93-8cce-0c41ed9b6a8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Stops by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "36940253-5d87-4d42-bbfb-1a4d9409916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          GEOID                                           geometry  \\\n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "\n",
      "         DATE  STOPS_BY_DAY  \n",
      "0  2025-01-01            80  \n",
      "0  2025-01-02            85  \n",
      "0  2025-01-03            58  \n",
      "0  2025-01-04           118  \n",
      "0  2025-01-05            64  \n",
      "0  2025-01-06            79  \n",
      "0  2025-01-07           121  \n",
      "0  2025-01-08           124  \n",
      "0  2025-01-09           140  \n",
      "0  2025-01-10            41  \n",
      "0  2025-01-11           104  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rf2694\\AppData\\Local\\anaconda3\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "#STOPS BY DAY DATASET (2025)\n",
    "dataByDay25 = bigData25[[\"GEOID\",\"geometry\",\"DATE_RANGE_START\",\"DATE_RANGE_END\",\"STOPS_BY_DAY\"]]\n",
    "#dataByDay25 = dataByDay25.dropna()\n",
    "dataByDay25['STOPS_BY_DAY'] = dataByDay25['STOPS_BY_DAY'].apply(literal_eval) #changes type from string to actual list lol\n",
    "dataByDate25 = dataByDay25.explode('STOPS_BY_DAY') #boom!\n",
    "\n",
    "day25 = pd.date_range(start=bigData25['DATE_RANGE_START'][0], end=bigData25['DATE_RANGE_END'][0]).strftime(\"%Y-%m-%d\").tolist()\n",
    "day25 = day25[0:31] #every date in january 2025, not including feb 1\n",
    "dates25 = day25 * len(dataByDay25)\n",
    "dataByDate25['DATE']=dates25\n",
    "dataByDateClean25 = dataByDate25[[\"GEOID\",\"geometry\",\"DATE\", \"STOPS_BY_DAY\"]]\n",
    "dataByDateClean25 = dataByDateClean25.astype({'STOPS_BY_DAY': 'int64'})\n",
    "print(dataByDateClean25[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7a8eb4eb-51c2-42a6-90dc-67a8b7a3223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to shapefile\n",
    "#note that variable names >10 characters will get cut off. just rename in QGIS idk\n",
    "dataByDateClean25.to_file(\"J25_daily.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "55364bff-4000-4d8a-9780-021990ed8841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          GEOID                                           geometry  \\\n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "\n",
      "         DATE  STOPS_BY_DAY  \n",
      "0  2024-01-01           199  \n",
      "0  2024-01-02           164  \n",
      "0  2024-01-03           117  \n",
      "0  2024-01-04           165  \n",
      "0  2024-01-05           269  \n",
      "0  2024-01-06            58  \n",
      "0  2024-01-07            98  \n",
      "0  2024-01-08           228  \n",
      "0  2024-01-09           264  \n",
      "0  2024-01-10           198  \n",
      "0  2024-01-11           260  \n"
     ]
    }
   ],
   "source": [
    "#STOPS BY DAY DATASET (2024)\n",
    "dataByDay24 = bigData24[[\"GEOID\",\"geometry\",\"DATE_RANGE_START\",\"DATE_RANGE_END\",\"STOPS_BY_DAY\"]]\n",
    "dataByDay24 = dataByDay24.dropna()\n",
    "dataByDay24['STOPS_BY_DAY'] = dataByDay24['STOPS_BY_DAY'].apply(literal_eval) #changes type from string to actual list lol\n",
    "dataByDate24 = dataByDay24.explode('STOPS_BY_DAY') #boom!\n",
    "\n",
    "day24 = pd.date_range(start=bigData24['DATE_RANGE_START'][0], end=bigData24['DATE_RANGE_END'][0]).strftime(\"%Y-%m-%d\").tolist()\n",
    "day24 = day24[0:31] #every date in january 2024, not including feb 1\n",
    "dates24 = day24 * len(dataByDay24)\n",
    "dataByDate24['DATE']=dates24\n",
    "dataByDateClean24 = dataByDate24[[\"GEOID\",\"geometry\",\"DATE\", \"STOPS_BY_DAY\"]]\n",
    "dataByDateClean24 = dataByDateClean24.astype({'STOPS_BY_DAY': 'int64'})\n",
    "print(dataByDateClean24[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7d6015af-6d11-4292-8093-64e758abf6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rf2694\\AppData\\Local\\Temp\\ipykernel_2908\\2719369358.py:3: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  dataByDateClean24.to_file(\"J24_daily.shp\")\n",
      "C:\\Users\\rf2694\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'STOPS_BY_DAY' to 'STOPS_BY_D'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "#write to shapefile\n",
    "#note that variable names >10 characters will get cut off. just rename in QGIS idk\n",
    "dataByDateClean24.to_file(\"J24_daily.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "56c70f3e-56bc-4d27-8ad0-ef64a35c22e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          GEOID                                           geometry  \\\n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...   \n",
      "\n",
      "         DATE  STOPS_BY_DAY  \n",
      "2  2025-01-01            80  \n",
      "2  2025-01-02            85  \n",
      "2  2025-01-03            58  \n",
      "2  2025-01-04           118  \n",
      "2  2025-01-05            64  \n",
      "2  2025-01-06            79  \n",
      "2  2025-01-07           121  \n",
      "2  2025-01-08           124  \n",
      "2  2025-01-09           140  \n",
      "2  2025-01-10            41  \n",
      "2  2025-01-11           104  \n"
     ]
    }
   ],
   "source": [
    "#STOPS BY DAY DATASET (Filtered from US)\n",
    "dataByDayUS = filteredbigDataUS[[\"GEOID\",\"geometry\",\"DATE_RANGE_START\",\"DATE_RANGE_END\",\"STOPS_BY_DAY\"]]\n",
    "dataByDayUS = dataByDayUS.dropna()\n",
    "dataByDayUS['STOPS_BY_DAY'] = dataByDayUS['STOPS_BY_DAY'].apply(literal_eval) #changes type from string to actual list lol\n",
    "dataByDateUS = dataByDayUS.explode('STOPS_BY_DAY') #boom!\n",
    "\n",
    "dayUS = pd.date_range(start=bigDataUS['DATE_RANGE_START'][2], end=filteredbigDataUS['DATE_RANGE_END'][2]).strftime(\"%Y-%m-%d\").tolist()\n",
    "dayUS = dayUS[0:31] #every date in january 2025, not including feb 1\n",
    "datesUS = dayUS * len(dataByDayUS)\n",
    "dataByDateUS['DATE']=datesUS\n",
    "dataByDateCleanUS = dataByDateUS[[\"GEOID\",\"geometry\",\"DATE\", \"STOPS_BY_DAY\"]]\n",
    "dataByDateCleanUS = dataByDateCleanUS.astype({'STOPS_BY_DAY': 'int64'})\n",
    "print(dataByDateCleanUS[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "86f0bbb2-e56c-42e4-a586-0864d016f14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rf2694\\AppData\\Local\\Temp\\ipykernel_2908\\2722370566.py:3: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  dataByDateClean24.to_file(\"US25_daily.shp\")\n",
      "C:\\Users\\rf2694\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'STOPS_BY_DAY' to 'STOPS_BY_D'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "#write to shapefile\n",
    "#note that variable names >10 characters will get cut off. just rename in QGIS idk\n",
    "dataByDateClean24.to_file(\"US25_daily.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae25f7-b596-46e9-87dc-9684fdfd7a66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Stops by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fc3d7795-ad53-4ee8-970b-b470ad26752b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2908\\338913447.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataByHour25\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbigData25\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"GEOID\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"geometry\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"STOPS_BY_EACH_HOUR\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'POPULARITY_BY_EACH_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataByHour25\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataByHour25\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataByHour25\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STOPS_BY_EACH_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataByHour25\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STOPS_BY_EACH_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdataByHour25\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POPULARITY_BY_EACH_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataByHour25\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POPULARITY_BY_EACH_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdataByHours25\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataByHour25\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STOPS_BY_EACH_HOUR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'POPULARITY_BY_EACH_HOUR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#boom!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#adding information about the hour of data and date range after explosion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mhours25\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataByHour25\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mday25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\geopandas\\geodataframe.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, column, ignore_index, index_parts, **kwargs)\u001b[0m\n\u001b[0;32m   2175\u001b[0m         \u001b[1;31m# If no column is specified then default to the active geometry column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2177\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2178\u001b[0m         \u001b[1;31m# If the specified column is not a geometry dtype use pandas explode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2179\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGeometryDtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2180\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2182\u001b[0m         \u001b[0mexploded_geom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_parts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "#STOPS BY HOUR DATASET\n",
    "dataByHour25 = bigData25[[\"GEOID\",\"geometry\",\"STOPS_BY_EACH_HOUR\",'POPULARITY_BY_EACH_HOUR']]\n",
    "dataByHour25 = dataByHour25.dropna()\n",
    "dataByHour25['STOPS_BY_EACH_HOUR'] = dataByHour25['STOPS_BY_EACH_HOUR'].apply(literal_eval)\n",
    "dataByHour25['POPULARITY_BY_EACH_HOUR'] = dataByHour25['POPULARITY_BY_EACH_HOUR'].apply(literal_eval)\n",
    "dataByHours25 = dataByHour25.explode(['STOPS_BY_EACH_HOUR','POPULARITY_BY_EACH_HOUR']) #boom!\n",
    "\n",
    "#adding information about the hour of data and date range after explosion\n",
    "hours25 = list(range(0,24)) * len(dataByHour25) * len(day25)\n",
    "dataByHours25['HOUR'] = hours25 \n",
    "daysHours25 = []\n",
    "for i in range(0,len(day25)):\n",
    "    daysHours25 += [day25[i]] * 24\n",
    "hourlyDate25 = daysHours25 * len(dataByHour25)\n",
    "dataByHours25['DATE'] = hourlyDate25\n",
    "\n",
    "print(dataByHours25[0:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac44ba-7cc0-44c8-ba76-bfe059b87294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOPS BY HOUR DATASET\n",
    "dataByHour24 = bigData24[[\"GEOID\",\"geometry\",\"STOPS_BY_EACH_HOUR\",'POPULARITY_BY_EACH_HOUR']]\n",
    "dataByHour24 = dataByHour24.dropna()\n",
    "dataByHour24['STOPS_BY_EACH_HOUR'] = dataByHour24['STOPS_BY_EACH_HOUR'].apply(literal_eval)\n",
    "dataByHour24['POPULARITY_BY_EACH_HOUR'] = dataByHour24['POPULARITY_BY_EACH_HOUR'].apply(literal_eval)\n",
    "dataByHours24 = dataByHour24.explode(['STOPS_BY_EACH_HOUR','POPULARITY_BY_EACH_HOUR']) #boom!\n",
    "\n",
    "#adding information about the hour of data and date range after explosion\n",
    "hours24 = list(range(0,24)) * len(dataByHour24) * len(day24)\n",
    "dataByHours24['HOUR'] = hours24 \n",
    "daysHours24 = []\n",
    "for i in range(0,len(day24)):\n",
    "    daysHours24 += [day24[i]] * 24\n",
    "hourlyDate24 = daysHours24 * len(dataByHour24)\n",
    "dataByHours24['DATE'] = hourlyDate24\n",
    "\n",
    "print(dataByHours24[0:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc82f7-120b-4309-9f4a-49378e329a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAW COMPARISONS\n",
    "dataByDateClean25.to_csv(\"Commerce-StopsByDay-Jan2025.csv\")\n",
    "dataByDateClean24.to_csv(\"Commerce-StopsByDay-Jan2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe058ee2-446a-4df4-b28c-c6b6544fda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data25.loc[data25['AREA'] == 360610095001]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6620ad-7ebc-46b7-8a19-2b90ebd3f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to get day by day weather data to reduce differences (thanks Dane)\n",
    "#url = 'https://www.wunderground.com/history/monthly/us/ny/new-york-city/KLGA/date/2025-1'\n",
    "#html = requests.get(url).content\n",
    "df_list = pd.read_html(\"weather24.htm\")\n",
    "df = df_list[-1]\n",
    "print(df)\n",
    "df.to_csv('my data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51155186-3e0b-4abf-9eb0-b9f2eae3863f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## General Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f8748fdc-4010-4127-a441-cc68550197af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates \"day\" category to specify day separate from year\n",
    "#https://stackoverflow.com/questions/39908314/slice-all-strings-in-a-list\n",
    "dataByDateClean25 = dataByDateClean25.astype({'DATE': 'string'})\n",
    "dataByDateClean25['day']= [word[5:] for word in dataByDateClean25['DATE']]\n",
    "dataByDateClean24 = dataByDateClean24.astype({'DATE': 'string'})\n",
    "dataByDateClean24['day']= [word[5:] for word in dataByDateClean24['DATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "78f2b787-5564-45a2-89be-5429f0fb79e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>geom</th>\n",
       "      <th>day</th>\n",
       "      <th>stops25</th>\n",
       "      <th>stops24</th>\n",
       "      <th>percchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360610080005</td>\n",
       "      <td>POLYGON ((990301.416 213054.566, 990434.901 21...</td>\n",
       "      <td>01-01</td>\n",
       "      <td>80</td>\n",
       "      <td>199</td>\n",
       "      <td>-59.798995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360610080005</td>\n",
       "      <td>POLYGON ((990301.416 213054.566, 990434.901 21...</td>\n",
       "      <td>01-02</td>\n",
       "      <td>85</td>\n",
       "      <td>164</td>\n",
       "      <td>-48.170732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360610080005</td>\n",
       "      <td>POLYGON ((990301.416 213054.566, 990434.901 21...</td>\n",
       "      <td>01-03</td>\n",
       "      <td>58</td>\n",
       "      <td>117</td>\n",
       "      <td>-50.427350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360610080005</td>\n",
       "      <td>POLYGON ((990301.416 213054.566, 990434.901 21...</td>\n",
       "      <td>01-04</td>\n",
       "      <td>118</td>\n",
       "      <td>165</td>\n",
       "      <td>-28.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360610080005</td>\n",
       "      <td>POLYGON ((990301.416 213054.566, 990434.901 21...</td>\n",
       "      <td>01-05</td>\n",
       "      <td>64</td>\n",
       "      <td>269</td>\n",
       "      <td>-76.208178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID                                               geom    day  \\\n",
       "0  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...  01-01   \n",
       "1  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...  01-02   \n",
       "2  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...  01-03   \n",
       "3  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...  01-04   \n",
       "4  360610080005  POLYGON ((990301.416 213054.566, 990434.901 21...  01-05   \n",
       "\n",
       "   stops25  stops24  percchange  \n",
       "0       80      199  -59.798995  \n",
       "1       85      164  -48.170732  \n",
       "2       58      117  -50.427350  \n",
       "3      118      165  -28.484848  \n",
       "4       64      269  -76.208178  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average per day per zone\n",
    "#https://stackoverflow.com/questions/53549492/joining-two-pandas-dataframes-based-on-multiple-conditions\n",
    "zoneavg = dataByDateClean25.merge(dataByDateClean24, how='inner', on=['GEOID','day'])\n",
    "zoneavg = zoneavg[['GEOID','geometry_x','day','stopsbyday','STOPS_BY_DAY']]\n",
    "zoneavg = zoneavg.rename(columns={'stopsbyday':'stops25','STOPS_BY_DAY':'stops24','geometry_x':'geom'})\n",
    "zoneavg['percchange'] = zoneavg['stops25']/zoneavg['stops24']*100 -100\n",
    "zoneavg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3d5003e9-e2ec-41e3-aa8d-16d20ec8c61f",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'zonechanges.shp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[210], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mzoneavg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzonechanges.shp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m zoneavg\u001b[38;5;241m.\u001b[39mto_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzonechanges.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\geopandas\\geodataframe.py:1536\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[1;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m \n\u001b[0;32m   1443\u001b[0m \u001b[38;5;124;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1532\u001b[0m \n\u001b[0;32m   1533\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[1;32m-> 1536\u001b[0m \u001b[43m_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:686\u001b[0m, in \u001b[0;36m_to_file\u001b[1;34m(df, filename, driver, schema, index, mode, crs, engine, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 686\u001b[0m     \u001b[43m_to_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    688\u001b[0m     _to_file_fiona(df, filename, driver, schema, crs, mode, metadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:748\u001b[0m, in \u001b[0;36m_to_file_pyogrio\u001b[1;34m(df, filename, driver, schema, crs, mode, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoDataFrame cannot contain duplicated column names.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 748\u001b[0m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyogrio\\geopandas.py:662\u001b[0m, in \u001b[0;36mwrite_dataframe\u001b[1;34m(df, path, layer, driver, encoding, geometry_type, promote_to_multi, nan_as_null, append, use_arrow, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m geometry_column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    660\u001b[0m     geometry \u001b[38;5;241m=\u001b[39m to_wkb(geometry\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m--> 662\u001b[0m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyogrio\\raw.py:723\u001b[0m, in \u001b[0;36mwrite\u001b[1;34m(path, geometry, field_data, fields, field_mask, layer, driver, geometry_type, crs, encoding, promote_to_multi, nan_as_null, append, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, gdal_tz_offsets, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;66;03m# preprocess kwargs and split in dataset and layer creation options\u001b[39;00m\n\u001b[0;32m    719\u001b[0m dataset_kwargs, layer_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_kwargs(\n\u001b[0;32m    720\u001b[0m     driver, dataset_options, layer_options, kwargs\n\u001b[0;32m    721\u001b[0m )\n\u001b[1;32m--> 723\u001b[0m \u001b[43mogr_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:2307\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_write\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:2102\u001b[0m, in \u001b[0;36mpyogrio._io.create_ogr_dataset_layer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'zonechanges.shp'"
     ]
    }
   ],
   "source": [
    "zoneavg.to_file(\"zonechanges.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0a0d6b1f-ca4d-4e95-9a7c-6002cf34de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "za = zoneavg[['GEOID','day','stops24','stops25','percchange']]\n",
    "za.to_csv(\"zonechanges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "80bf2235-eda0-461a-83f2-3484ea99a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoneavgClean = zoneavg[(zoneavg.stops24 != 0) & (zoneavg.stops25 != 0)] #removes values of -100% change and inf (both issues with missing values)\n",
    "zoneavgClean.head()\n",
    "zoneavgClean.to_file(\"zonechangesClean.shp\")\n",
    "zoneavgClean.to_csv(\"zonechangesClean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef6ba9-a6ef-4871-a9e3-c67b9c3e70cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
